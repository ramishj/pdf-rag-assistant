#!/usr/bin/env python3
"""
Demo script for PDF Knowledge Assistant
Shows how to use the core functionality programmatically
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add the current directory to Python path
sys.path.append(str(Path(__file__).parent))

from app import PDFProcessor, VectorDatabase, LLMProvider

def demo_pdf_processing():
    """Demonstrate PDF processing capabilities"""
    print("üìÑ PDF Processing Demo")
    print("=" * 40)
    
    # Initialize processor
    processor = PDFProcessor()
    print("‚úÖ PDF Processor initialized")
    
    # Sample text for demonstration
    sample_text = """
    This is a sample document about artificial intelligence and machine learning.
    AI has revolutionized many industries including healthcare, finance, and transportation.
    Machine learning algorithms can now process vast amounts of data to identify patterns.
    Deep learning has enabled breakthroughs in computer vision and natural language processing.
    The future of AI holds great promise for solving complex problems.
    """
    
    # Process text
    chunks = processor.chunk_text(sample_text, chunk_size=100, overlap=20)
    print(f"‚úÖ Text chunked into {len(chunks)} segments")
    
    # Create embeddings
    embeddings = processor.create_embeddings(chunks)
    print(f"‚úÖ Created {len(embeddings)} embeddings")
    
    return processor, chunks, embeddings

def demo_vector_database(chunks, embeddings):
    """Demonstrate vector database operations"""
    print("\nüóÑÔ∏è Vector Database Demo")
    print("=" * 40)
    
    # Initialize database
    vector_db = VectorDatabase()
    collection_name = "demo_collection"
    
    # Create collection
    vector_db.create_collection(collection_name)
    print(f"‚úÖ Created collection: {collection_name}")
    
    # Add documents
    metadata = [
        {
            "filename": "demo_doc.txt",
            "chunk_index": i,
            "total_chunks": len(chunks),
            "demo": True
        }
        for i in range(len(chunks))
    ]
    
    vector_db.add_documents(chunks, embeddings, metadata)
    print(f"‚úÖ Added {len(chunks)} documents to database")
    
    return vector_db

def demo_search_and_query(vector_db, processor):
    """Demonstrate search and query capabilities"""
    print("\nüîç Search and Query Demo")
    print("=" * 40)
    
    # Test queries
    test_queries = [
        "What is artificial intelligence?",
        "How does machine learning work?",
        "What are the applications of AI?"
    ]
    
    for query in test_queries:
        print(f"\nQuery: {query}")
        
        # Search for similar documents
        results = vector_db.search_similar(query, processor.embeddings_model, n_results=2)
        
        if results and results['documents']:
            print("Relevant context found:")
            for i, doc in enumerate(results['documents'][0]):
                print(f"  {i+1}. {doc[:100]}...")
        else:
            print("No relevant context found")
    
    return test_queries

def demo_llm_providers():
    """Demonstrate LLM provider setup"""
    print("\nü§ñ LLM Provider Demo")
    print("=" * 40)
    
    providers = ["OpenAI", "Claude", "Azure", "Grok"]
    
    for provider in providers:
        print(f"\nProvider: {provider}")
        
        # Get API key from environment
        api_key = os.getenv(f"{provider.upper()}_API_KEY")
        
        if api_key and api_key != "your_api_key_here":
            print(f"‚úÖ API key found for {provider}")
            
            # For Azure, also check endpoint
            azure_endpoint = None
            if provider == "Azure":
                azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
                if azure_endpoint:
                    print(f"‚úÖ Azure endpoint found: {azure_endpoint}")
                else:
                    print("‚ö†Ô∏è  No Azure endpoint found")
                    continue
            
            # Try to initialize provider
            try:
                llm = LLMProvider(provider, api_key, azure_endpoint=azure_endpoint)
                if llm.client:
                    print(f"‚úÖ {provider} client initialized successfully")
                    
                    # Test Azure-specific functionality
                    if provider == "Azure":
                        print(f"   Using endpoint: {azure_endpoint}")
                        print(f"   Default model: gpt-4o")
                else:
                    print(f"‚ö†Ô∏è  {provider} client initialization failed")
            except Exception as e:
                print(f"‚ùå Error initializing {provider}: {str(e)}")
        else:
            print(f"‚ö†Ô∏è  No API key found for {provider}")
            if provider == "Azure":
                print(f"   Set {provider.upper()}_API_KEY and AZURE_OPENAI_ENDPOINT in your .env file")
            else:
                print(f"   Set {provider.upper()}_API_KEY in your .env file")

def demo_azure_integration():
    """Demonstrate Azure OpenAI integration specifically"""
    print("\nüîµ Azure OpenAI Integration Demo")
    print("=" * 40)
    
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    
    if api_key and endpoint and api_key != "your_api_key_here":
        print("‚úÖ Azure credentials found")
        print(f"   Endpoint: {endpoint}")
        
        try:
            # Test Azure client initialization
            llm = LLMProvider("Azure", api_key, "gpt-4o", endpoint)
            if llm.client:
                print("‚úÖ Azure OpenAI client initialized successfully")
                
                # Test a simple query
                test_response = llm.generate_response(
                    "What is the capital of France?", 
                    "France is a country in Europe."
                )
                print(f"‚úÖ Test query successful: {test_response[:100]}...")
            else:
                print("‚ùå Azure client initialization failed")
        except Exception as e:
            print(f"‚ùå Azure integration error: {str(e)}")
    else:
        print("‚ö†Ô∏è  Azure credentials not found")
        print("   Set AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT in your .env file")

def main():
    """Run the complete demo"""
    print("üöÄ PDF Knowledge Assistant Demo")
    print("=" * 50)
    
    try:
        # Demo 1: PDF Processing
        processor, chunks, embeddings = demo_pdf_processing()
        
        # Demo 2: Vector Database
        vector_db = demo_vector_database(chunks, embeddings)
        
        # Demo 3: Search and Query
        test_queries = demo_search_and_query(vector_db, processor)
        
        # Demo 4: LLM Providers
        demo_llm_providers()
        
        # Demo 5: Azure Integration
        demo_azure_integration()
        
        print("\n" + "=" * 50)
        print("üéâ Demo completed successfully!")
        print("\nüìã What we demonstrated:")
        print("‚Ä¢ PDF text processing and chunking")
        print("‚Ä¢ Vector database operations")
        print("‚Ä¢ Similarity search functionality")
        print("‚Ä¢ LLM provider configuration")
        print("‚Ä¢ Azure OpenAI direct integration")
        print("\nüöÄ Ready to run the full application!")
        print("Run: python3 run.py")
        
    except Exception as e:
        print(f"\n‚ùå Demo failed: {str(e)}")
        print("Please check your setup and try again")

if __name__ == "__main__":
    main()
